
# Exâ€‘Claim ğŸš©

**Entity-aware Crossâ€‘lingual Claim Detection for Automated Factâ€‘Checking**

---

## ğŸ” Overview

**Exâ€‘Claim** introduces an entity-aware model for cross-lingual verifiable claim detection. Leveraging named entity recognition and entity linking, this model effectively identifies factual claims in multilingual social media postsâ€”even in languages unseen during training. Its design supports robust knowledge transfer across languages.  
[ğŸ“„ View the paper on arXiv](https://arxiv.org/pdf/2503.15220)

---

## âœ¨ Key Features

- **Entity-aware prediction**: Integrates multilingual Named Entity Recognition (MultiNERD) and Entity Linking (mGENERE) to include entity type and popularity signals.
- **Cross-lingual generalisation**: Fine-tuned with XLMâ€‘R embeddings, achieving consistent gain across 27 languages, including unseen ones during training.
- **Modular architecture**: Offers variantsâ€”**Xâ€‘Claim** (baseline), **EXNâ€‘Claim** (add entity types), and **EXPâ€‘Claim** (add entity popularity).

---

## ğŸ“š Research Insight

A parallel paper details the model and experiments:

- **Title**: *Entity-aware Cross-lingual Claim Detection for Automated Fact-checking*  
- **Authors**: R. Panchendrarajan & A. Zubiaga  
- **Published**: arXiv, 2025  
- **Link**: [arxiv.org/abs/2503.15220](https://arxiv.org/abs/2503.15220)

---

## ğŸš€ Installation

```bash
git clone https://github.com/RubaP/Ex-Claim.git
cd Ex-Claim
pip install -r requirements.txt
```

---

## ğŸ§  Model Variants

| Variant      | Components                               | Description                                       |
|--------------|------------------------------------------|---------------------------------------------------|
| **Xâ€‘Claim**   | XLMâ€‘R embeddings                          | Multilingual baseline without entity features     |
| **EXNâ€‘Claim** | XLMâ€‘R + Named-entity type embeddings      | Adds entity-type awareness                        |
| **EXPâ€‘Claim** | XLMâ€‘R + Entity type & popularity embeddings | Adds entity popularity from Entity Linking                  |

---

## ğŸ“Š Evaluation & Results

- Tested across **3 datasets** covering **27 languages**, including synthetic data via machine translation.
- **EXPâ€‘Claim** consistently outperformed baselines like mBERT, XLMâ€‘R, and mT5.
- Achieved **~87% cross-lingual transferability**, outperforming the baselines.

---

## ğŸ§ª Datasets

- **CheckThat! 2022** (Twitter) - COVID-19 tweets written in 5 languages
- **Synthetic Data** â€“ synthetically translation of CheckThat! Test data across 18 languages
- **Kazemi** (WhatsApp Tiplines) â€“ COVID-19 and Political posts written in 5 languages

---

## ğŸš§ Known Limitations

- **COVID-19 domain bias** â€“ most training data are COVID-related tweets.
- **NER/EL limitations** â€“ model performance can degrade with poor tagging in low-resource languages.
- **False predictions** â€“ struggles with personal-experience phrasing or visual/multimodal claims.

---


## ğŸ—‚ï¸ Project Structure

The repository is organized modularly under a `src/` directory, with distinct folders handling different components of the claim detection pipeline:

```
src/
â”œâ”€â”€ analysis/         # Scripts for analyzing model behavior and errors
â”œâ”€â”€ data/             # Scripts for synthetic data generation
â”œâ”€â”€ evaluation/       # Claim detection logic and entity linking tuning
â”œâ”€â”€ models/           # Core model architecture for claim detection
â”œâ”€â”€ util/             # Utility modules: NER, entity linking, training, evaluation, etc.
```

### ğŸ“ analysis/
Scripts to analyze the behavior and performance of trained models:
- `analyse_attention_weights.py` â€“ Visualize self-attention weights.
- `compute_attention_entropy.py` â€“ Measure uncertainty via entropy.
- `error_analysis.py` â€“ Examine false positives/negatives.
- `knowledge_transfer.py` â€“ Study multilingual knowledge transfer.
- `visualize_entity_embeddings.py` â€“ Plot entity embeddings in 2D.

### ğŸ“ data/
Handles data generation:
- `generateSyntheticTestData.py` â€“ Translates test data to new languages.

### ğŸ“ evaluation/
Core scripts for model experimentation:
- `claim-detection.py` â€“ Baselines and X-Claim for claim classification.
- `claim-detectionE.py` â€“ EX-Claim Pipeline implementation.
- `entity-linking-parameter-tuning.py` â€“ Optimizes EL thresholds.

### ğŸ“ models/
Contains model architecture:
- `ClaimDetection.py` â€“ Defines the neural network, attention mechanisms, and entity fusion layers.

### ğŸ“ util/
Reusable components used across the project:
- `Embedding.py` â€“ Handles word/entity embeddings.
- `EntityLinking.py` â€“ Entity disambiguation and popularity lookup.
- `Evaluation.py` â€“ Model performance metrics.
- `NER.py` â€“ Multilingual named entity recognition interface.
- `Preprocess.py` â€“ Tokenization, entity tagging, and input prep.
- `ReadDataset.py` â€“ Dataset loaders and formatters.
- `Results.py` â€“ Aggregates and saves experiment results.
- `Training.py` â€“ Model training logic.
- `Util.py` â€“ Miscellaneous helper functions.


## ğŸ“„ Citation

If you use **Exâ€‘Claim**, please cite:

```bibtex
@inproceedings{panchendrarajan2025exclaim,
  title={Entity-aware Cross-lingual Claim Detection for Automated Fact-checking},
  author={Panchendrarajan, Rruba and Zubiaga, Arkaitz},
  booktitle={arXiv preprint arXiv:2503.15220},
  year={2025}
}
```

---

## ğŸ“§ Contact

For questions or suggestions, open an issue or contact:

**Rruba Panchendrarajan** â€“ r.panchendrarajan@qmul.ac.uk  
GitHub: [@RubaP](https://github.com/RubaP)

---
